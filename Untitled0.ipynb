{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# وارد کردن کتابخانه‌های اولیه\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "rKTESmRHAkCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. نصب کتابخونه‌های مورد نیاز با نسخه‌های سازگار\n",
        "def install_dependencies():\n",
        "    print(\"نصب کتابخونه‌ها...\")\n",
        "    os.system(\"pip install -q numpy==1.24.3 librosa==0.10.1 noisereduce==2.0.1 pydub==0.25.1 openai-whisper==20231117 hazm==0.10.0 torch==2.0.1 transformers==4.38.2\")\n"
      ],
      "metadata": {
        "id": "lqT77WMlAkbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. وارد کردن کتابخونه‌ها\n",
        "def import_libraries():\n",
        "    global whisper, AudioSegment, nr, np, files, librosa, Normalizer, WordTokenizer, stopwords_list, AutoTokenizer, AutoModelForTokenClassification, pipeline, torch\n",
        "    try:\n",
        "        import whisper\n",
        "        from pydub import AudioSegment\n",
        "        import noisereduce as nr\n",
        "        import numpy as np\n",
        "        from google.colab import files\n",
        "        import librosa\n",
        "        from hazm import Normalizer, WordTokenizer, stopwords_list\n",
        "        from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "        import torch\n",
        "    except ModuleNotFoundError as e:\n",
        "        print(f\"خطا در وارد کردن کتابخونه‌ها: {e}\")\n",
        "        print(\"تلاش دوباره برای نصب...\")\n",
        "        install_dependencies()\n",
        "        import whisper\n",
        "        from pydub import AudioSegment\n",
        "        import noisereduce as nr\n",
        "        import numpy as np\n",
        "        from google.colab import files\n",
        "        import librosa\n",
        "        from hazm import Normalizer, WordTokenizer, stopwords_list\n",
        "        from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "        import torch"
      ],
      "metadata": {
        "id": "ReBwO79bAmNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. پیدا کردن فایل‌های صوتی آپلودشده\n",
        "def find_audio_files():\n",
        "    print(\"جستجوی فایل‌های صوتی در دایرکتوری Colab...\")\n",
        "    supported_formats = [\".wav\", \".mp3\", \".flac\"]\n",
        "    audio_files = [f for f in os.listdir() if os.path.splitext(f)[1].lower() in supported_formats]\n",
        "    if not audio_files:\n",
        "        print(\"هیچ فایل صوتی پیدا نشد! لطفاً فایل‌ها را آپلود کنید:\")\n",
        "        uploaded = files.upload()\n",
        "        audio_files = list(uploaded.keys())\n",
        "    return audio_files"
      ],
      "metadata": {
        "id": "N7HoIhLwApne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. پردازش و بهینه‌سازی فایل صوتی\n",
        "def preprocess_audio(audio_path, chunk_duration_ms=30000):\n",
        "    print(f\"پردازش فایل صوتی: {audio_path}\")\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
        "\n",
        "        chunks = [audio[i:i+chunk_duration_ms] for i in range(0, len(audio), chunk_duration_ms)]\n",
        "        chunk_paths = []\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            chunk_path = f\"temp_chunk_{os.path.basename(audio_path)}_{i}.wav\"\n",
        "            chunk.export(chunk_path, format=\"wav\")\n",
        "\n",
        "            y, sr = librosa.load(chunk_path, sr=16000)\n",
        "            y_reduced = nr.reduce_noise(y=y, sr=sr, stationary=False)\n",
        "            AudioSegment(\n",
        "                y_reduced.tobytes(),\n",
        "                frame_rate=sr,\n",
        "                sample_width=y_reduced.dtype.itemsize,\n",
        "                channels=1\n",
        "            ).export(chunk_path, format=\"wav\")\n",
        "            chunk_paths.append(chunk_path)\n",
        "\n",
        "        return chunk_paths\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"خطا در پردازش صوت: {str(e)}\")\n"
      ],
      "metadata": {
        "id": "N1nUSBueAtxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. تبدیل صوت به متن با Whisper\n",
        "def transcribe_audio(chunk_paths, use_large_model=True):\n",
        "    print(\"بارگذاری مدل Whisper...\")\n",
        "    model_name = \"large-v3\" if use_large_model else \"medium\"\n",
        "    try:\n",
        "        model = whisper.load_model(model_name)\n",
        "    except Exception as e:\n",
        "        print(f\"خطا در بارگذاری مدل {model_name}: {e}. استفاده از مدل medium...\")\n",
        "        model = whisper.load_model(\"medium\")\n",
        "\n",
        "    transcribed_text = \"\"\n",
        "    timestamps = []\n",
        "\n",
        "    print(\"تبدیل صوت به متن...\")\n",
        "    for chunk_path in chunk_paths:\n",
        "        try:\n",
        "            result = model.transcribe(\n",
        "                chunk_path,\n",
        "                language=\"fa\",\n",
        "                fp16=False,\n",
        "                verbose=False,\n",
        "                task=\"transcribe\"\n",
        "            )\n",
        "            transcribed_text += result[\"text\"] + \" \"\n",
        "            for segment in result[\"segments\"]:\n",
        "                timestamps.append({\n",
        "                    \"text\": segment[\"text\"],\n",
        "                    \"start\": segment[\"start\"],\n",
        "                    \"end\": segment[\"end\"]\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"خطا در پردازش چانک {chunk_path}: {e}\")\n",
        "\n",
        "    return transcribed_text.strip(), timestamps\n"
      ],
      "metadata": {
        "id": "x54ov5T2AxLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. پردازش NLP با Hazm و ParsBERT\n",
        "def process_nlp(transcribed_text, enable_ner=True):\n",
        "    print(\"پردازش NLP...\")\n",
        "\n",
        "    try:\n",
        "        normalizer = Normalizer()\n",
        "        normalized_text = normalizer.normalize(transcribed_text)\n",
        "\n",
        "        tokenizer = WordTokenizer()\n",
        "        tokens = tokenizer.tokenize(normalized_text)\n",
        "        stopwords = stopwords_list()\n",
        "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
        "\n",
        "        entities = []\n",
        "        if enable_ner:\n",
        "            print(\"استخراج موجودیت‌های نام‌دار (NER)...\")\n",
        "            try:\n",
        "                ner_tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")\n",
        "                ner_model = AutoModelForTokenClassification.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")\n",
        "                ner_pipeline = pipeline(\"ner\", model=ner_model, tokenizer=ner_tokenizer)\n",
        "                ner_results = ner_pipeline(normalized_text)\n",
        "                entities = [\n",
        "                    {\"word\": entity[\"word\"], \"entity\": entity[\"entity\"], \"score\": entity[\"score\"]}\n",
        "                    for entity in ner_results if entity[\"entity\"].startswith((\"B-\", \"I-\"))\n",
        "                ]\n",
        "            except Exception as e:\n",
        "                print(f\"خطا در NER: {e}. ادامه بدون NER...\")\n",
        "\n",
        "        return {\n",
        "            \"normalized_text\": normalized_text,\n",
        "            \"tokens\": filtered_tokens,\n",
        "            \"entities\": entities\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"خطا در پردازش NLP: {e}\")\n",
        "        return {\n",
        "            \"normalized_text\": transcribed_text,\n",
        "            \"tokens\": [],\n",
        "            \"entities\": []\n",
        "        }"
      ],
      "metadata": {
        "id": "kk0dwDDvBQLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. ذخیره و دانلود خروجی‌ها\n",
        "def save_and_download_results(audio_file, transcribed_text, nlp_results, timestamps):\n",
        "    print(f\"ذخیره نتایج برای {audio_file}...\")\n",
        "    base_name = os.path.splitext(audio_file)[0]\n",
        "\n",
        "    text_file = f\"{base_name}_transcribed.txt\"\n",
        "    with open(text_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(transcribed_text)\n",
        "\n",
        "    nlp_file = f\"{base_name}_nlp_results.txt\"\n",
        "    with open(nlp_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"متن نرمال‌شده:\\n\")\n",
        "        f.write(nlp_results[\"normalized_text\"] + \"\\n\\n\")\n",
        "        f.write(\"توکن‌های فیلترشده:\\n\")\n",
        "        f.write(str(nlp_results[\"tokens\"]) + \"\\n\\n\")\n",
        "        f.write(\"موجودیت‌های نام‌دار:\\n\")\n",
        "        f.write(str(nlp_results[\"entities\"]) + \"\\n\")\n",
        "\n",
        "    timestamps_file = f\"{base_name}_timestamps.txt\"\n",
        "    with open(timestamps_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        for ts in timestamps:\n",
        "            f.write(f\"Text: {ts['text']} | Start: {ts['start']}s | End: {ts['end']}s\\n\")\n",
        "\n",
        "    try:\n",
        "        files.download(text_file)\n",
        "        files.download(nlp_file)\n",
        "        files.download(timestamps_file)\n",
        "    except Exception as e:\n",
        "        print(f\"خطا در دانلود فایل‌ها: {e}. فایل‌ها در دایرکتوری Colab ذخیره شدند.\")"
      ],
      "metadata": {
        "id": "kiw0AL0-BWsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. پاک‌سازی فایل‌های موقت\n",
        "def cleanup(chunk_paths):\n",
        "    print(\"پاک‌سازی فایل‌های موقت...\")\n",
        "    for chunk_path in chunk_paths:\n",
        "        if os.path.exists(chunk_path):\n",
        "            os.remove(chunk_path)"
      ],
      "metadata": {
        "id": "bbKcnXl-BbyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. اجرای اصلی\n",
        "def main():\n",
        "    try:\n",
        "        install_dependencies()\n",
        "        import_libraries()\n",
        "\n",
        "        audio_files = find_audio_files()\n",
        "        print(f\"فایل‌های صوتی پیدا شده: {audio_files}\")\n",
        "\n",
        "        for audio_file in audio_files:\n",
        "            print(f\"\\nپردازش فایل: {audio_file}\")\n",
        "            chunk_paths = preprocess_audio(audio_file)\n",
        "            transcribed_text, timestamps = transcribe_audio(chunk_paths, use_large_model=True)\n",
        "            nlp_results = process_nlp(transcribed_text, enable_ner=True)\n",
        "            save_and_download_results(audio_file, transcribed_text, nlp_results, timestamps)\n",
        "            cleanup(chunk_paths)\n",
        "\n",
        "        print(\"\\nپردازش همه فایل‌ها با موفقیت انجام شد!\")\n",
        "    except Exception as e:\n",
        "        print(f\"خطا رخ داد: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-RjYAoBBd6X",
        "outputId": "920c5ec9-4807-4764-b69e-e14e9b38e2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "نصب کتابخونه‌ها...\n",
            "خطا رخ داد: module 'numpy' has no attribute 'dtypes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. نصب تمیز کتابخونه‌ها\n",
        "def install_dependencies():\n",
        "    print(\"حذف نسخه‌های قدیمی کتابخونه‌ها...\")\n",
        "    os.system(\"pip uninstall -y numpy librosa noisereduce pydub openai-whisper hazm torch transformers\")\n",
        "    print(\"نصب کتابخونه‌ها با نسخه‌های سازگار...\")\n",
        "    os.system(\"pip install -q numpy==1.24.3 librosa==0.10.1 noisereduce==2.0.1 pydub==0.25.1 openai-whisper==20231117 hazm==0.10.0 torch==2.0.1 transformers==4.38.2\")"
      ],
      "metadata": {
        "id": "kI7BGujzBf7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "didL71mZCWTI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}